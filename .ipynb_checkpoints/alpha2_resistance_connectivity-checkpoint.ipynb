{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this investigation is to demonstrate the effects of $\\color{blue}{\\alpha_1}$ and $\\color{red}{\\alpha_2}$ on the potential connectivity of a landscape with a fixed covariate surface.\n",
    "\n",
    "Potential connectivity is given by sum of use probabilities:\n",
    "\n",
    "$$C^P(i) = \\sum_{j} Pr(g[i,j])$$ \n",
    "$$ Pr(g[i,j]) = e^{-\\color{blue}{\\alpha_1} d_{ecol}(i,j)^2}\n",
    "= \\left( e^{d_{ecol}(i,j)^2} \\right)^{-\\color{blue}{\\alpha_1}}\n",
    "= \\left( e^{d_{ecol}(i,j)^2} \\right)^{-\\color{blue}{\\frac{1}{2\\sigma^2}}}$$\n",
    "\n",
    "So, **$\\alpha_1$ modulates the rate at which ecological distance causes use probabilities to decay**; larger $\\alpha_1$ values lead to a more rapid decay. This is like an animal species that is less willing to move through large ecological distances.\n",
    "\n",
    "Ecological distance is given by:\n",
    "\n",
    "$$d_{ecol}(i,j) = min_{\\mathcal{L}} \\sum_{p=1}^{m+1} cost(v_p,v_{p+1}) d_{euc}(v_p, v_{p+1}) \n",
    "= min_{\\mathcal{L}} \\sum_{p=1}^{m+1} e^{\\alpha_2 \\frac{z(v_p) + z(v_{p+1})}{2}} d_{euc}(v_p, v_{p+1}) \n",
    "= min_{\\mathcal{L}} \\sum_{p=1}^{m+1} \\left(e^{\\frac{z(v_p) + z(v_{p+1})}{2}}\\right)^{\\color{red}{\\alpha_2}} d_{euc}(v_p, v_{p+1})$$\n",
    "\n",
    "Therefore, **$\\alpha_2$ modulates the extent to which the landscape covariate increases the ecological distance**. In our current experiments, high covariate values represent high resistance to movement and poor habitat, so larger $\\alpha_2$ values lead to a stronger dependence of ecological distance on covariate values. This is like an animal species whose movement is highly affected by the covariate surface. $\\alpha_2=0$ reduces to the case of using Euclidean distance.\n",
    "\n",
    "Both higher $\\color{blue}{\\alpha_1}$ and $\\color{red}{\\alpha_2}$ work to reduce the use probabilities $Pr(g[i,j])$. Hence, an increase in $\\color{red}{\\alpha_2}$ can be counteracted by a decrease in $\\color{blue}{\\alpha_1}$, which is precisely the mechanism used to maintain home ranges at a constant size under the two $\\color{red}{\\alpha_2}$ settings. For example, when an animal species's movement is highly affected by (sensitive to) the covariate surface (high $\\alpha_2$), precicted ecological distances will be higher than Euclidean, but to keep home range size constant we will choose low $\\alpha_1$ to make the species less sensitive to ecological distances overall. First, let us check whether the home ranges are indeed about the same size for both settings.\n",
    "\n",
    ">I proceed by using a single covariate surface and computing the use probabilities under the two different $(\\alpha_1, \\alpha_2)$ scenarios. The target home range size is 64 pixels. *****I computed $\\alpha_1$ value for each resistance setting using the corresponding effective sigma values taken from Dana's manuscript:\n",
    "$$\\alpha_2 = 0.25 \\implies \\sigma_{effective} = 0.1677509 \\implies \\alpha_1 = 17.76807123$$\n",
    "$$\\alpha_2 = 1.75 \\implies \\sigma_{effective} = 0.3749552 \\implies \\alpha_1 = 3.55640524856$$\n",
    "Given the covariate surface, I compute the $d_{ecol}(i,j)$ (least-cost shortest paths) under each setting. (Note, I do not know what order of magnitude the $d_{euc}(v_p, v_{p+1})$ distances actually are; I set the distance between horizontally/vertically adjacent pixels to be $0.1$ units, so the distance between diagonally adjacent pixels is $\\sqrt{(0.1)^2+(0.1)^2}$ units and the distance between the neighbors from the 16-pixel neighborhood is $\\sqrt{(0.1)^2+(0.2)^2}$; this gives me use probability values that are comparable to the values in the potmat matrices I am working with.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import rasterio\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def compute_ecological_distances(landscape, a2):\n",
    "    # computes the ecological distance between every pair of pixels in a landscape\n",
    "    # inputs:    landscape    -    covariate values\n",
    "    #            a2           -    alpha2\n",
    "    # outputs:   apsp        -    all pairs shortest path lengths\n",
    "    nrow = len(landscape)\n",
    "    ncol = len(landscape[0])\n",
    "    \n",
    "    print(\"Computing the ecological distances for %s-by-%s covariate surface %s.\\na2 = %s\"%(nrow,ncol,covariatedatafilename,a2))\n",
    "    \n",
    "    # create the graph\n",
    "    nodes = [_ for _ in range(nrow*ncol)]\n",
    "    #pos = [] # positions for visualizing using nx.draw()\n",
    "    graph = nx.Graph()\n",
    "    pix_length = 0.1\n",
    "    edge_length = {4: 0, 8: 0, 16: 0}\n",
    "    edge_length[4] = pix_length\n",
    "    edge_length[8] = math.sqrt(pix_length**2 + pix_length**2)\n",
    "    edge_length[16] = math.sqrt(pix_length**2 + (2*pix_length)**2)\n",
    "    for n in nodes:\n",
    "        graph.add_node(n)\n",
    "        col = n/ncol\n",
    "        row = n%ncol\n",
    "        #pos.append((row, col))\n",
    "    for r in range(nrow-1):\n",
    "        for c in range(ncol):\n",
    "            # north edges across rows # 4-neighborhood\n",
    "            graph.add_edge(r*ncol + c, (r+1)*ncol + c, weight=edge_length[4]*math.exp(a2*(landscape[r][c]+landscape[r+1][c])/2))\n",
    "        for c in range(ncol-1):\n",
    "            # north-east edges across rows (row and col increasing) # 8-neighborhood\n",
    "            graph.add_edge(r*ncol + c, (r+1)*ncol + c + 1, weight=edge_length[8]*math.exp(a2*(landscape[r][c]+landscape[r+1][c+1])/2))\n",
    "        for c in range(ncol-2):\n",
    "            # east-north-east edge # 16-neighborhood\n",
    "            graph.add_edge(r*ncol + c, (r+1)*ncol + c + 2, weight=edge_length[16]*math.exp(a2*(landscape[r][c]+landscape[r+1][c+2])/2))\n",
    "    for r in range(nrow-2):\n",
    "        for c in range(ncol-1):\n",
    "            # north-north-east edge # 16-neighborhood\n",
    "            graph.add_edge(r*ncol + c, (r+2)*ncol + c + 1, weight=edge_length[16]*math.exp(a2*(landscape[r][c]+landscape[r+2][c+1])/2))\n",
    "    for c in range(ncol-1):\n",
    "        for r in range(nrow):\n",
    "            # horizontal edges across columns # 4-neighborhood\n",
    "            graph.add_edge(r*ncol + c, r*ncol + c + 1, weight=edge_length[4]*math.exp(a2*(landscape[r][c]+landscape[r][c+1])/2))\n",
    "        for r in range(1,nrow):\n",
    "            # diagonal edges across rows (row decreasing col increasing) # 8-neighborhood\n",
    "            graph.add_edge(r*ncol + c, (r-1)*ncol + c + 1, weight=edge_length[8]*math.exp(a2*(landscape[r][c]+landscape[r-1][c+1])/2))\n",
    "        for r in range(2,nrow):\n",
    "            # south-south-east edge # 16-neighborhood\n",
    "            graph.add_edge(r*ncol + c, (r-2)*ncol + c + 1, weight=edge_length[16]*math.exp(a2*(landscape[r][c]+landscape[r-2][c+1])/2))\n",
    "    for c in range(ncol-2):\n",
    "        for r in range(1,nrow):\n",
    "            # east-south-east edge # 16-neighborhood\n",
    "            graph.add_edge(r*ncol + c, (r-1)*ncol + c + 2, weight=edge_length[16]*math.exp(a2*(landscape[r][c]+landscape[r-1][c+2])/2))\n",
    "    graph = graph.to_undirected()\n",
    "    \n",
    "    # compute all pair shortest paths\n",
    "    apsp = nx.all_pairs_dijkstra_path_length(graph)\n",
    "    #print(\"Finished computing all pairs shortest paths.\")\n",
    "    return apsp\n",
    "\n",
    "def compute_use_probabilities(ecological_distance, es, a0 = 1):\n",
    "    # given ecological distances for a landscape, computes the use probabilities\n",
    "    # inputs:    ecological_distance     -    computed pairwise ecological distances\n",
    "    #            es                      -    effective sigma used to compute\n",
    "    #            a0                      -    alpha0 detection probability, default value 1\n",
    "    # outputs:   useprobs                -    all pairs shortest path lengths\n",
    "    print(\"a0 = %s\"%(a0))\n",
    "    a1 = 1/(2*es*es)\n",
    "    print(\"a1 = %s (es = %s)\"%(a1, es))\n",
    "    npix = len(ecological_distance)\n",
    "    useprobs = np.zeros((npix, npix))\n",
    "    for j in range(npix):\n",
    "        for i in range(npix):\n",
    "            d = ecological_distance[i][j]\n",
    "            useprobs[i][j] = a0*(math.exp(-(d*d)))**a1\n",
    "    return useprobs\n",
    "\n",
    "def compute_potential_connectivities(use_probs):\n",
    "    # given use probabilities for a landscape, computes the potential connectivity for each pixel\n",
    "    # inputs:    use_probs     -    computed pairwise use probabilities\n",
    "    # outputs:   pc            -    potential connectivity values\n",
    "    npix = len(use_probs)\n",
    "    pc = np.zeros(npix)\n",
    "    for j in range(npix):\n",
    "        jsum = 0\n",
    "        for i in range(npix):\n",
    "            jsum = jsum + use_probs[i][j]\n",
    "        pc[j] = jsum\n",
    "    return(pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "covariatedatafilename = \"../../Documents/LandscapeConnectivity/scropt/data/simcov_a2025_S100_cov.tif\"\n",
    "covariatesurfacedata = rasterio.open(covariatedatafilename)\n",
    "covariatesurface = covariatesurfacedata.read().squeeze()\n",
    "\n",
    "npix = 1600\n",
    "alpha2 = [0.25, 1.75]\n",
    "effsig = [0.1677509, 0.3749552]\n",
    "decol = dict()\n",
    "useprobs = dict()\n",
    "pc = dict()\n",
    "for a2idx in range(len(alpha2)):\n",
    "    decol[alpha2[a2idx]] = compute_ecological_distances(covariatesurface,alpha2[a2idx])\n",
    "    useprobs[alpha2[a2idx]] = compute_use_probabilities(decol[alpha2[a2idx]], effsig[a2idx])\n",
    "    pc[alpha2[a2idx]] = compute_potential_connectivities(useprobs[alpha2[a2idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,4))\n",
    "hrsize = dict()\n",
    "bin_boundaries = np.linspace(0,120,61)\n",
    "# print(bin_boundaries)\n",
    "for a2idx in range(len(alpha2)):\n",
    "    hrsize[alpha2[a2idx]] = []\n",
    "    potmat = useprobs[alpha2[a2idx]]\n",
    "    low = potmat < 0.01\n",
    "    potmat[low] = 0\n",
    "    for p in range(1600):\n",
    "        hrsize[alpha2[a2idx]].append((potmat[p,]!=0).sum())\n",
    "    print(\"a2: %s    theta: %s    smallest HR: %s    biggest HR: %s    mean HR: %s\"%(alpha2[a2idx], effsig[a2idx], min(hrsize[alpha2[a2idx]]), max(hrsize[alpha2[a2idx]]), np.mean(hrsize[alpha2[a2idx]])))\n",
    "    plt.subplot(1,2,a2idx+1)\n",
    "    n, bins, patches = plt.hist(hrsize[alpha2[a2idx]],bins=bin_boundaries)\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([0,120])\n",
    "    axes.set_ylim([0,280])\n",
    "    plt.xlabel(\"Home Range Size (number of pixels)\\nMean Home Range Size: %s\"%np.mean(hrsize[alpha2[a2idx]]))\n",
    "    plt.title(r'$\\alpha_2$=%s, $\\theta$=%s'%(alpha2[a2idx], effsig[a2idx]),fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of home range sizes looks very different for our two $(\\alpha_1, \\alpha_2)$ settings. The mean home range sizes are 57.57 (60.11 reported in manuscript) and 60.98 (60.45 reported in manuscript). Although these are close to the reported values, the $\\alpha_2=0.25$ setting mean home range size is on average smaller than the $\\alpha_2=1.75$ setting. Furthermore, the spread of home range sizes differs significantly between settings. For $\\alpha_2=0.25$, $(min, max)=(20,69)$ (manuscript reports $(53,64)$) and for $\\alpha_2=1.75$, $(min,max)=(11,114)$ (manuscript reports $(23, 91)$). Again, these are close to the values reported in the manuscript, showing that the combined effect of high $\\alpha_2$ and corresponding $\\theta$ is to cause greater variability in home range size while keeping the mean home range size approximately the same.\n",
    "\n",
    "One reflection is that the home ranges in the high $\\alpha_2$ setting might be expected to have a bimodal distribution--those activity centers that happen to be located in areas of high covariate (high resistance) should have small home ranges size, while those that are in low-covariate areas should have large home range sizes. Inspecting individual home ranges seems to demonstrate this effect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acs = [495, 1235, 518, 825]\n",
    "for ac in acs:\n",
    "    plt.figure(figsize = (12,2))\n",
    "    \n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(covariatesurface, interpolation='nearest', cmap=cm.RdYlGn_r, alpha=1.0, origin=\"lower\") # interpolation can be nearest, bilinear, bicubic\n",
    "    plt.colorbar()\n",
    "    plt.grid(False)\n",
    "    plt.title('Simulated Covariate Data', fontsize=12)\n",
    "    \n",
    "    plt.subplot(1,3,2)\n",
    "    potmat = useprobs[0.25]\n",
    "    low = potmat < 0.05\n",
    "    potmat[low] = 0\n",
    "    hrac = potmat[ac,].reshape(40,40)\n",
    "    plt.imshow(hrac, interpolation='nearest', cmap=cm.RdYlGn, alpha=1.0, vmin=0, vmax=1, origin=\"lower\")\n",
    "    plt.colorbar()\n",
    "    plt.title(r'Home range %s, $\\alpha_2=0.25$'%(ac), fontsize=12)\n",
    "    plt.xlabel('Number of pixels: %s,\\nPotential Connectivity: %s'%((potmat[ac,]!=0).sum(), potmat[ac,].sum()))\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    potmat = useprobs[1.75]\n",
    "    low = potmat < 0.05\n",
    "    potmat[low] = 0\n",
    "    hrac = potmat[ac,].reshape(40,40)\n",
    "    plt.imshow(hrac, interpolation='nearest', cmap=cm.RdYlGn, alpha=1.0, vmin=0, vmax=1, origin=\"lower\")\n",
    "    plt.colorbar()\n",
    "    plt.title(r'Home range %s, $\\alpha_2=1.75$'%(ac), fontsize=12)\n",
    "    plt.xlabel('Number of pixels: %s,\\nPotential Connectivity: %s'%((potmat[ac,]!=0).sum(), potmat[ac,].sum()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The effect of the parameter settings on the use probabilities (and subsequently the potential connectivity) with increasing ecological distance is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decol_list = dict()\n",
    "useprobs_list = dict()\n",
    "for a2idx in range(len(alpha2)):\n",
    "    decol_list[alpha2[a2idx]] = []\n",
    "    useprobs_list[alpha2[a2idx]] = []\n",
    "    for i in range(npix):\n",
    "        for j in range(npix):\n",
    "            decol_list[alpha2[a2idx]].append(decol[alpha2[a2idx]][i][j])\n",
    "            useprobs_list[alpha2[a2idx]].append(useprobs[alpha2[a2idx]][i][j])\n",
    "decolscaleidx = sorted(range(len(decol_list)), key=lambda k: decol_list[k])\n",
    "decolscale = decol_list[decolscaleidx]\n",
    "useprobsscale = useprobs_list[decolscaleidx]\n",
    "#     # collect path lengths\n",
    "#     decol = []\n",
    "#     useprobs[a2] = np.zeros((nrow*ncol, nrow*ncol))\n",
    "#     pc[a2] = np.zeros(nrow*ncol)\n",
    "#     for j in nodes:\n",
    "#         jsum = 0\n",
    "#         for i in nodes:\n",
    "#             d = apsp[i][j]\n",
    "#             decol.append(d)\n",
    "#             useprobs[a2][i][j] = a0*(math.exp(-(d*d)))**a1\n",
    "#             jsum = jsum + useprobs[a2][i][j]\n",
    "#         pc[a2][j] = jsum\n",
    "# #         if isum>0:\n",
    "# #             print(isum)\n",
    "#     pc[a2] = pc[a2].reshape(40,40)\n",
    "            \n",
    "    \n",
    "#     # turn into x axis \"scale\" by eliminating duplicate values and sorting\n",
    "#     decolscale = sorted(set(decol))\n",
    "    \n",
    "#     # compute pij's\n",
    "#     pij = []\n",
    "#     for d in decolscale:\n",
    "#         pij.append(a0*(math.exp(-(d*d)))**a1)\n",
    "#     plt.subplot(1,2,1)\n",
    "#     plt.loglog(decolscale, pij)\n",
    "#     plt.subplot(1,2,2)\n",
    "#     plt.semilogy(decolscale, pij) # we will zoom in to this plot\n",
    "\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.legend(alpha2, loc=\"lower left\")\n",
    "# plt.xlabel(r'$d_{ecol}$', fontsize=20)\n",
    "# plt.ylabel(r'$p_{ij}$', fontsize=20)\n",
    "# axes = plt.gca()\n",
    "# axes.set_xlim([0,100])\n",
    "\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.legend(alpha2, loc=\"lower left\")\n",
    "# plt.xlabel(r'$d_{ecol}$', fontsize=20)\n",
    "# plt.ylabel(r'$p_{ij}$', fontsize=20)\n",
    "# axes = plt.gca()\n",
    "# axes.set_xlim([0,1])\n",
    "# axes.set_ylim([10e-15,1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The right graph is a zoomed-in version of the left graph. Both show that for any value for ecological distance, the use probability is higher for the $\\alpha_2=1.75$ case than for the $\\alpha_2=0.25$ case. To verify that my computations for $d_{ecol}$ and $p_{ij}$ were correct, I compared the potential connectivity surface from my recomputations with that provided with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(pc[0.25], interpolation='nearest', cmap=cm.RdYlGn, alpha=1.0, origin=\"lower\") # interpolation can be nearest, bilinear, bicubic\n",
    "print(\"Max pc, recomputed: %s\"%pc[0.25].max())\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.title(r'PC$(\\alpha_2=0.25)$, recomputed', fontsize=15)\n",
    "# plt.show()\n",
    "datasetfilename = \"../Desktop/hropt/Data/simcov_a2025_S100_pc.tif\"\n",
    "with rasterio.open(datasetfilename) as src:\n",
    "    r = src.read()\n",
    "    data = r.squeeze()\n",
    "    print(\"Max pc, data: %s\"%data.max())\n",
    "    data = np.transpose(data)\n",
    "#     plt.figure(figsize=(5, 4))\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(data, interpolation='nearest', cmap=cm.RdYlGn, alpha=1.0, origin=\"lower\") # interpolation can be nearest, bilinear, bicubic\n",
    "    plt.colorbar()\n",
    "    plt.grid(False)\n",
    "    plt.title(r'PC$(\\alpha_2=0.25)$, from data', fontsize=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(pc[1.75], interpolation='nearest', cmap=cm.RdYlGn, alpha=1.0, origin=\"lower\") # interpolation can be nearest, bilinear, bicubic\n",
    "print(\"Max pc, recomputed: %s\"%pc[1.75].max())\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.title(r'PC$(\\alpha_2=1.75)$, recomputed', fontsize=15)\n",
    "# plt.show()\n",
    "datasetfilename = \"../Desktop/hropt/Data/simcov_a2175_S100_pc.tif\"\n",
    "with rasterio.open(datasetfilename) as src:\n",
    "    r = src.read()\n",
    "    data = r.squeeze()\n",
    "    print(\"Max pc, data: %s\"%data.max())\n",
    "    data = np.transpose(data)\n",
    "#     plt.figure(figsize=(5, 4))\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(data, interpolation='nearest', cmap=cm.RdYlGn, alpha=1.0, origin=\"lower\") # interpolation can be nearest, bilinear, bicubic\n",
    "    plt.colorbar()\n",
    "    plt.grid(False)\n",
    "    plt.title(r'PC$(\\alpha_2=1.75)$, from data', fontsize=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And comparing the distributions of pixel-wise potential connectivities $C^P(i)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pcvals025 = pc[0.25].reshape(1600,1)\n",
    "pcvals175 = pc[1.75].reshape(1600,1)\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "n, bins, patches = plt.hist(pcvals025,50)\n",
    "# plt.ylabel('Potential Connectivity')\n",
    "plt.xlabel('Potential Connectivity\\nTotal: %s, Mean: %s'%(sum(pcvals025)[0], np.mean(pcvals025)))\n",
    "plt.title(r'$\\alpha_2=0.25$',fontsize=15)\n",
    "plt.subplot(1,2,2)\n",
    "n, bins, patches = plt.hist(pcvals175,50)\n",
    "plt.title(r'$\\alpha_2=1.75$', fontsize=15)\n",
    "plt.xlabel('Potential Connectivity\\nTotal: %s, Mean: %s'%(sum(pcvals175)[0], np.mean(pcvals175)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The recomputed potential connectivity surfaces look qualitatively similar to those from the dataset, and differences can probably be attributed to the distances I used between adjacent pixels. The higher potential connectivity in the $\\alpha_2=1.75$ case suggests that the willingness of the animals to travel greater ecological distances ($\\color{blue}{\\alpha_1}$) overpowers the increased perceived ecological distance caused by the covariate surface ($\\color{red}{\\alpha_2}$). In a real case study, there is only one value of $\\alpha_2$ for the species and only one corresponding $\\alpha_1$ value. However, if we want to compare landscape reserve design for animals whose movement is either strongly or weakly linked to the covariate surface, i.e. treating $\\alpha_2$ as the (only) resistance parameter, this \"willingness\" caused by $\\alpha_1$ may be a confounding factor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Since we are interested in maintaining home range size constant, I examined the distributions of home range sizes (using the 99% home range size to try to get the mean home range size of ~64 pixels reported in the manuscript). However, **I got home range sizes of ~52 and ~56 pixels for $\\alpha_2=0.25$ and $\\alpha_2=1.75$ respectively, with widely differing distributions**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,4))\n",
    "plt.subplot(1,2,1)\n",
    "hrsize = []\n",
    "potmat = useprobs[0.25]\n",
    "low = potmat < 0.01\n",
    "potmat[low] = 0\n",
    "for p in range(1600):\n",
    "    hrsize.append((potmat[p,]!=0).sum())\n",
    "n, bins, patches = plt.hist(hrsize,50)\n",
    "# plt.ylabel(\"Home Range Size (number of pixels)\")\n",
    "plt.xlabel(\"Home Range Size (number of pixels)\\nMean Home Range Size: %s\"%np.mean(hrsize))\n",
    "plt.title(r'$\\alpha_2=0.25$',fontsize=15)\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "hrsize = []\n",
    "potmat = useprobs[1.75]\n",
    "low = potmat < 0.01\n",
    "potmat[low] = 0\n",
    "for p in range(1600):\n",
    "    hrsize.append((potmat[p,]!=0).sum())\n",
    "n, bins, patches = plt.hist(hrsize,50)\n",
    "plt.xlabel(\"Home Range Size (number of pixels)\\nMean Home Range Size: %s\"%np.mean(hrsize))\n",
    "plt.title(r'$\\alpha_2=1.75$',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we inspect the 95% home range for a particular activity center. Two are shown below. It appears that for activity centers in areas of low covariate (low resistance) such as pixels 125 and 110, the $\\alpha_2 = 1.75$ case has a larger home range with higher use probabilities than for the low-resistance case. This can be seen by the darker green coloring (higher use probabilities) in $\\alpha_2=1.75$ of the 8 pixels immediately surrounding activity center 110, and the higher potential connectivity of the pixel. More pixels must be conserved in order to protect these home ranges, but the subsequent connectivity reward is higher. Conversely, in areas with high covariate (high resistance) such as around pixels 475 and 825, the $\\alpha_2 = 1.75$ case has a smaller home range with lower total potential connectivity. Fewer pixels are needed to conserve these home ranges, but the connectivity gain is smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In order to explore the implications of high $\\alpha_2$ for reserve planning, while maintaining mean home range size roughly constant, one possibility could be to examine why the mean home range size is larger for $\\alpha_2=1.75$ (since it is supposed to be the same by choice of effective sigma) and see if correcting for this will help reduce the overall potential connectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
